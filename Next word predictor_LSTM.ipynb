{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv5JpYDcYwMY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "IrmA3eaj3kF0"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers.\n",
        "These neural networks attempt to simulate the behavior of the human brain—albeit far from matching its ability—allowing it\n",
        "to “learn” from large amounts of data. While a neural network with a single layer can still make approximate predictions,\n",
        "additional hidden layers can help to optimize and refine for accuracy.\n",
        "Deep learning drives many artificial intelligence (AI) applications and services that improve automation,\n",
        "performing analytical and physical tasks without human intervention. Deep learning technology lies behind everyday products and services\n",
        "(such as digital assistants, voice-enabled TV remotes, and credit card fraud detection) as well as emerging technologies (such as self-driving cars).\n",
        "If deep learning is a subset of machine learning, how do they differ? Deep learning distinguishes itself from classical machine learning by the type\n",
        "of data that it works with and the methods in which it learns.\n",
        "Machine learning algorithms leverage structured,\n",
        "labeled data to make predictions—meaning that specific features are defined from the input data for the model and organized into tables.\n",
        "This doesn’t necessarily mean that it doesn’t use unstructured data; it just means that if it does,\n",
        "it generally goes through some pre-processing to organize it into a structured format.\n",
        "Deep learning eliminates some of data pre-processing that is typically involved with machine learning.\n",
        "These algorithms can ingest and process unstructured data, like text and images, and it automates feature extraction,\n",
        "removing some of the dependency on human experts. For example, let’s say that we had a set of photos of different pets,\n",
        "and we wanted to categorize by “cat”, “dog”, “hamster”, et cetera. Deep learning algorithms can determine\n",
        "which features (e.g. ears) are most important to distinguish each animal from another.\n",
        "In machine learning, this hierarchy of features is established manually by a human expert.\n",
        "Then, through the processes of gradient descent and backpropagation, the deep learning algorithm adjusts and fits itself for accuracy,\n",
        "allowing it to make predictions about a new photo of an animal with increased precision.\n",
        "Machine learning and deep learning models are capable of different types of learning as well,\n",
        "which are usually categorized as supervised learning,\n",
        "unsupervised learning, and reinforcement learning. Supervised learning utilizes labeled datasets to categorize or make predictions;\n",
        "this requires some kind of human intervention to label input data correctly.\n",
        "In contrast, unsupervised learning doesn’t require labeled datasets, and instead, it detects patterns in the data,\n",
        "clustering them by any distinguishing characteristics. Reinforcement learning is a process in which a model learns to\n",
        "become more accurate for performing an action in an environment based on feedback in order to maximize the reward.\n",
        "Deep learning neural networks, or artificial neural networks, attempts to mimic the human brain through a combination of data inputs,\n",
        "weights, and bias. These elements work together to accurately recognize, classify, and describe objects within the data.\n",
        "Deep neural networks consist of multiple layers of interconnected nodes, each building upon the previous layer to refine and\n",
        "optimize the prediction or categorization. This progression of computations through the network is called forward propagation.\n",
        "The input and output layers of a deep neural network are called visible layers.\n",
        "The input layer is where the deep learning model ingests the data for processing, and the output layer is where the final prediction or classification is made.\n",
        "Another process called backpropagation uses algorithms, like gradient descent, to calculate errors in predictions and then adjusts\n",
        "the weights and biases of the function by moving backwards through the layers in an effort to train the model. Together,\n",
        "forward propagation and backpropagation allow a neural network to make predictions and correct for any errors accordingly.\n",
        "Over time, the algorithm becomes gradually more accurate.\n",
        "The above describes the simplest type of deep neural network in the simplest terms. However,\n",
        "deep learning algorithms are incredibly complex, and there are different types of neural networks to address specific problems or datasets. For example,\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgvZVc6b8krz",
        "outputId": "0a1a8758-397d-4a2a-e8b2-901a30bd80c6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "d6jO-w7i8HPC"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tokenizer instance\n",
        "tokenizer = Tokenizer ()"
      ],
      "metadata": {
        "id": "mVMak8Mt8fPP"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the Tokenizer on the FAQs dataset to build the vocabulary.\n",
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "k5aj8S7m80aW"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOU3tTPI9IaJ",
        "outputId": "7b767aa4-9ecc-4161-972f-bf6891407f88"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#This code generates input sequences for text generation model training by breaking down sentences into sub-sequences.\n",
        "input_sequences=[]\n",
        "for sentence in faqs.split(\"\\n\"):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "vAadc_J99UAp"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm5kVBbL9UDJ",
        "outputId": "846c9009-58c6-4bf3-ed05-3ef5b1d39899"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 2],\n",
              " [6, 2, 10],\n",
              " [6, 2, 10, 7],\n",
              " [6, 2, 10, 7, 49],\n",
              " [6, 2, 10, 7, 49, 4],\n",
              " [6, 2, 10, 7, 49, 4, 14],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11, 17],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11, 17, 23],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11, 17, 23, 97],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11, 17, 23, 97, 18],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11, 17, 23, 97, 18, 38],\n",
              " [6, 2, 10, 7, 49, 4, 14, 2, 22, 10, 96, 7, 11, 17, 23, 97, 18, 38, 19],\n",
              " [39, 11],\n",
              " [39, 11, 24],\n",
              " [39, 11, 24, 98],\n",
              " [39, 11, 24, 98, 5],\n",
              " [39, 11, 24, 98, 5, 99],\n",
              " [39, 11, 24, 98, 5, 99, 1],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101, 102],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101, 102, 25],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101, 102, 25, 103],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101, 102, 25, 103, 104],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101, 102, 25, 103, 104, 105],\n",
              " [39, 11, 24, 98, 5, 99, 1, 100, 4, 1, 20, 101, 102, 25, 103, 104, 105, 9],\n",
              " [5, 106],\n",
              " [5, 106, 25],\n",
              " [5, 106, 25, 107],\n",
              " [5, 106, 25, 107, 108],\n",
              " [5, 106, 25, 107, 108, 4],\n",
              " [5, 106, 25, 107, 108, 4, 8],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23, 7],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23, 7, 110],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23, 7, 110, 31],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23, 7, 110, 31, 32],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23, 7, 110, 31, 32, 111],\n",
              " [5, 106, 25, 107, 108, 4, 8, 109, 7, 11, 17, 23, 7, 110, 31, 32, 111, 26],\n",
              " [5,\n",
              "  106,\n",
              "  25,\n",
              "  107,\n",
              "  108,\n",
              "  4,\n",
              "  8,\n",
              "  109,\n",
              "  7,\n",
              "  11,\n",
              "  17,\n",
              "  23,\n",
              "  7,\n",
              "  110,\n",
              "  31,\n",
              "  32,\n",
              "  111,\n",
              "  26,\n",
              "  112],\n",
              " [5,\n",
              "  106,\n",
              "  25,\n",
              "  107,\n",
              "  108,\n",
              "  4,\n",
              "  8,\n",
              "  109,\n",
              "  7,\n",
              "  11,\n",
              "  17,\n",
              "  23,\n",
              "  7,\n",
              "  110,\n",
              "  31,\n",
              "  32,\n",
              "  111,\n",
              "  26,\n",
              "  112,\n",
              "  27],\n",
              " [113, 114],\n",
              " [113, 114, 19],\n",
              " [113, 114, 19, 32],\n",
              " [113, 114, 19, 32, 115],\n",
              " [113, 114, 19, 32, 115, 5],\n",
              " [113, 114, 19, 32, 115, 5, 50],\n",
              " [113, 114, 19, 32, 115, 5, 50, 3],\n",
              " [113, 114, 19, 32, 115, 5, 50, 3, 51],\n",
              " [113, 114, 19, 32, 115, 5, 50, 3, 51, 13],\n",
              " [113, 114, 19, 32, 115, 5, 50, 3, 51, 13, 52],\n",
              " [6, 2],\n",
              " [6, 2, 116],\n",
              " [6, 2, 116, 117],\n",
              " [6, 2, 116, 117, 53],\n",
              " [6, 2, 116, 117, 53, 118],\n",
              " [6, 2, 116, 117, 53, 118, 119],\n",
              " [6, 2, 116, 117, 53, 118, 119, 120],\n",
              " [6, 2, 116, 117, 53, 118, 119, 120, 3],\n",
              " [6, 2, 116, 117, 53, 118, 119, 120, 3, 54],\n",
              " [6, 2, 116, 117, 53, 118, 119, 120, 3, 54, 15],\n",
              " [6, 2, 116, 117, 53, 118, 119, 120, 3, 54, 15, 121],\n",
              " [6, 2, 116, 117, 53, 118, 119, 120, 3, 54, 15, 121, 122],\n",
              " [55, 123],\n",
              " [55, 123, 3],\n",
              " [55, 123, 3, 124],\n",
              " [55, 123, 3, 124, 125],\n",
              " [55, 123, 3, 124, 125, 126],\n",
              " [55, 123, 3, 124, 125, 126, 20],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127, 128],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127, 128, 129],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127, 128, 129, 130],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127, 128, 129, 130, 131],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127, 128, 129, 130, 131, 3],\n",
              " [55, 123, 3, 124, 125, 126, 20, 56, 6, 2, 127, 128, 129, 130, 131, 3, 54],\n",
              " [57, 21],\n",
              " [57, 21, 132],\n",
              " [57, 21, 132, 133],\n",
              " [57, 21, 132, 133, 134],\n",
              " [57, 21, 132, 133, 134, 135],\n",
              " [57, 21, 132, 133, 134, 135, 136],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138, 139],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138, 139, 140],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138, 139, 140, 141],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138, 139, 140, 141, 21],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138, 139, 140, 141, 21, 58],\n",
              " [57, 21, 132, 133, 134, 135, 136, 137, 3, 138, 139, 140, 141, 21, 58, 21],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142,\n",
              "  143],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142,\n",
              "  143,\n",
              "  57],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142,\n",
              "  143,\n",
              "  57,\n",
              "  21],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142,\n",
              "  143,\n",
              "  57,\n",
              "  21,\n",
              "  144],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142,\n",
              "  143,\n",
              "  57,\n",
              "  21,\n",
              "  144,\n",
              "  145],\n",
              " [57,\n",
              "  21,\n",
              "  132,\n",
              "  133,\n",
              "  134,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  3,\n",
              "  138,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  21,\n",
              "  58,\n",
              "  21,\n",
              "  142,\n",
              "  143,\n",
              "  57,\n",
              "  21,\n",
              "  144,\n",
              "  145,\n",
              "  146],\n",
              " [59, 6],\n",
              " [59, 6, 2],\n",
              " [59, 6, 2, 10],\n",
              " [59, 6, 2, 10, 7],\n",
              " [59, 6, 2, 10, 7, 49],\n",
              " [59, 6, 2, 10, 7, 49, 4],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150, 6],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150, 6, 2],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150, 6, 2, 151],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150, 6, 2, 151, 60],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150, 6, 2, 151, 60, 25],\n",
              " [59, 6, 2, 10, 7, 49, 4, 14, 2, 147, 148, 149, 150, 6, 2, 151, 60, 25, 152],\n",
              " [59,\n",
              "  6,\n",
              "  2,\n",
              "  10,\n",
              "  7,\n",
              "  49,\n",
              "  4,\n",
              "  14,\n",
              "  2,\n",
              "  147,\n",
              "  148,\n",
              "  149,\n",
              "  150,\n",
              "  6,\n",
              "  2,\n",
              "  151,\n",
              "  60,\n",
              "  25,\n",
              "  152,\n",
              "  14],\n",
              " [59,\n",
              "  6,\n",
              "  2,\n",
              "  10,\n",
              "  7,\n",
              "  49,\n",
              "  4,\n",
              "  14,\n",
              "  2,\n",
              "  147,\n",
              "  148,\n",
              "  149,\n",
              "  150,\n",
              "  6,\n",
              "  2,\n",
              "  151,\n",
              "  60,\n",
              "  25,\n",
              "  152,\n",
              "  14,\n",
              "  2],\n",
              " [59,\n",
              "  6,\n",
              "  2,\n",
              "  10,\n",
              "  7,\n",
              "  49,\n",
              "  4,\n",
              "  14,\n",
              "  2,\n",
              "  147,\n",
              "  148,\n",
              "  149,\n",
              "  150,\n",
              "  6,\n",
              "  2,\n",
              "  151,\n",
              "  60,\n",
              "  25,\n",
              "  152,\n",
              "  14,\n",
              "  2,\n",
              "  28],\n",
              " [59,\n",
              "  6,\n",
              "  2,\n",
              "  10,\n",
              "  7,\n",
              "  49,\n",
              "  4,\n",
              "  14,\n",
              "  2,\n",
              "  147,\n",
              "  148,\n",
              "  149,\n",
              "  150,\n",
              "  6,\n",
              "  2,\n",
              "  151,\n",
              "  60,\n",
              "  25,\n",
              "  152,\n",
              "  14,\n",
              "  2,\n",
              "  28,\n",
              "  1],\n",
              " [59,\n",
              "  6,\n",
              "  2,\n",
              "  10,\n",
              "  7,\n",
              "  49,\n",
              "  4,\n",
              "  14,\n",
              "  2,\n",
              "  147,\n",
              "  148,\n",
              "  149,\n",
              "  150,\n",
              "  6,\n",
              "  2,\n",
              "  151,\n",
              "  60,\n",
              "  25,\n",
              "  152,\n",
              "  14,\n",
              "  2,\n",
              "  28,\n",
              "  1,\n",
              "  61],\n",
              " [4, 8],\n",
              " [4, 8, 15],\n",
              " [4, 8, 15, 9],\n",
              " [4, 8, 15, 9, 153],\n",
              " [4, 8, 15, 9, 153, 23],\n",
              " [4, 8, 15, 9, 153, 23, 3],\n",
              " [4, 8, 15, 9, 153, 23, 3, 1],\n",
              " [4, 8, 15, 9, 153, 23, 3, 1, 154],\n",
              " [4, 8, 15, 9, 153, 23, 3, 1, 154, 12],\n",
              " [4, 8, 15, 9, 153, 23, 3, 1, 154, 12, 22],\n",
              " [4, 8, 15, 9, 153, 23, 3, 1, 154, 12, 22, 9],\n",
              " [4, 8, 15, 9, 153, 23, 3, 1, 154, 12, 22, 9, 62],\n",
              " [14, 2],\n",
              " [14, 2, 29],\n",
              " [14, 2, 29, 155],\n",
              " [14, 2, 29, 155, 63],\n",
              " [40, 8],\n",
              " [40, 8, 5],\n",
              " [40, 8, 5, 26],\n",
              " [40, 8, 5, 26, 156],\n",
              " [40, 8, 5, 26, 156, 15],\n",
              " [40, 8, 5, 26, 156, 15, 64],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8, 13],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8, 13, 1],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8, 13, 1, 34],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8, 13, 1, 34, 3],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8, 13, 1, 34, 3, 158],\n",
              " [40, 8, 5, 26, 156, 15, 64, 41, 16, 157, 25, 1, 33, 8, 13, 1, 34, 3, 158, 65],\n",
              " [40,\n",
              "  8,\n",
              "  5,\n",
              "  26,\n",
              "  156,\n",
              "  15,\n",
              "  64,\n",
              "  41,\n",
              "  16,\n",
              "  157,\n",
              "  25,\n",
              "  1,\n",
              "  33,\n",
              "  8,\n",
              "  13,\n",
              "  1,\n",
              "  34,\n",
              "  3,\n",
              "  158,\n",
              "  65,\n",
              "  159],\n",
              " [35, 42],\n",
              " [35, 42, 160],\n",
              " [35, 42, 160, 161],\n",
              " [35, 42, 160, 161, 15],\n",
              " [35, 42, 160, 161, 15, 9],\n",
              " [35, 42, 160, 161, 15, 9, 42],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9, 163],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9, 163, 164],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9, 163, 164, 15],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9, 163, 164, 15, 59],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9, 163, 164, 15, 59, 9],\n",
              " [35, 42, 160, 161, 15, 9, 42, 162, 66, 8, 9, 163, 164, 15, 59, 9, 165],\n",
              " [9, 166],\n",
              " [9, 166, 167],\n",
              " [9, 166, 167, 30],\n",
              " [9, 166, 167, 30, 36],\n",
              " [9, 166, 167, 30, 36, 67],\n",
              " [9, 166, 167, 30, 36, 67, 43],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5, 168],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5, 168, 9],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5, 168, 9, 65],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5, 168, 9, 65, 7],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5, 168, 9, 65, 7, 63],\n",
              " [9, 166, 167, 30, 36, 67, 43, 5, 168, 9, 65, 7, 63, 169],\n",
              " [6, 2],\n",
              " [6, 2, 170],\n",
              " [6, 2, 170, 36],\n",
              " [6, 2, 170, 36, 4],\n",
              " [6, 2, 170, 36, 4, 8],\n",
              " [6, 2, 170, 36, 4, 8, 67],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15, 10],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15, 10, 171],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15, 10, 171, 172],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15, 10, 171, 172, 23],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15, 10, 171, 172, 23, 14],\n",
              " [6, 2, 170, 36, 4, 8, 67, 43, 15, 10, 171, 172, 23, 14, 2],\n",
              " [39, 29],\n",
              " [39, 29, 32],\n",
              " [39, 29, 32, 173],\n",
              " [39, 29, 32, 173, 3],\n",
              " [39, 29, 32, 173, 3, 44],\n",
              " [39, 29, 32, 173, 3, 44, 66],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3, 175],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3, 175, 3],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3, 175, 3, 9],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3, 175, 3, 9, 176],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3, 175, 3, 9, 176, 177],\n",
              " [39, 29, 32, 173, 3, 44, 66, 8, 68, 174, 3, 175, 3, 9, 176, 177, 178],\n",
              " [179, 36],\n",
              " [179, 36, 4],\n",
              " [179, 36, 4, 1],\n",
              " [179, 36, 4, 1, 180],\n",
              " [179, 36, 4, 1, 180, 69],\n",
              " [179, 36, 4, 1, 180, 69, 20],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183, 15],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183, 15, 71],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183, 15, 71, 184],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183, 15, 71, 184, 7],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183, 15, 71, 184, 7, 185],\n",
              " [179, 36, 4, 1, 180, 69, 20, 181, 13, 70, 182, 183, 15, 71, 184, 7, 185, 4],\n",
              " [179,\n",
              "  36,\n",
              "  4,\n",
              "  1,\n",
              "  180,\n",
              "  69,\n",
              "  20,\n",
              "  181,\n",
              "  13,\n",
              "  70,\n",
              "  182,\n",
              "  183,\n",
              "  15,\n",
              "  71,\n",
              "  184,\n",
              "  7,\n",
              "  185,\n",
              "  4,\n",
              "  186],\n",
              " [179,\n",
              "  36,\n",
              "  4,\n",
              "  1,\n",
              "  180,\n",
              "  69,\n",
              "  20,\n",
              "  181,\n",
              "  13,\n",
              "  70,\n",
              "  182,\n",
              "  183,\n",
              "  15,\n",
              "  71,\n",
              "  184,\n",
              "  7,\n",
              "  185,\n",
              "  4,\n",
              "  186,\n",
              "  4],\n",
              " [179,\n",
              "  36,\n",
              "  4,\n",
              "  1,\n",
              "  180,\n",
              "  69,\n",
              "  20,\n",
              "  181,\n",
              "  13,\n",
              "  70,\n",
              "  182,\n",
              "  183,\n",
              "  15,\n",
              "  71,\n",
              "  184,\n",
              "  7,\n",
              "  185,\n",
              "  4,\n",
              "  186,\n",
              "  4,\n",
              "  45],\n",
              " [179,\n",
              "  36,\n",
              "  4,\n",
              "  1,\n",
              "  180,\n",
              "  69,\n",
              "  20,\n",
              "  181,\n",
              "  13,\n",
              "  70,\n",
              "  182,\n",
              "  183,\n",
              "  15,\n",
              "  71,\n",
              "  184,\n",
              "  7,\n",
              "  185,\n",
              "  4,\n",
              "  186,\n",
              "  4,\n",
              "  45,\n",
              "  187],\n",
              " [3, 71],\n",
              " [3, 71, 188],\n",
              " [3, 71, 188, 5],\n",
              " [3, 71, 188, 5, 72],\n",
              " [3, 71, 188, 5, 72, 28],\n",
              " [3, 71, 188, 5, 72, 28, 189],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192, 193],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192, 193, 6],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192, 193, 6, 2],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192, 193, 6, 2, 29],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192, 193, 6, 2, 29, 32],\n",
              " [3, 71, 188, 5, 72, 28, 189, 190, 191, 192, 193, 6, 2, 29, 32, 194],\n",
              " [22, 41],\n",
              " [22, 41, 195],\n",
              " [22, 41, 195, 196],\n",
              " [22, 41, 195, 196, 197],\n",
              " [22, 41, 195, 196, 197, 16],\n",
              " [22, 41, 195, 196, 197, 16, 198],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199, 5],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199, 5, 200],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199, 5, 200, 73],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199, 5, 200, 73, 74],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199, 5, 200, 73, 74, 25],\n",
              " [22, 41, 195, 196, 197, 16, 198, 199, 5, 200, 73, 74, 25, 75],\n",
              " [12, 14],\n",
              " [12, 14, 2],\n",
              " [12, 14, 2, 35],\n",
              " [12, 14, 2, 35, 201],\n",
              " [12, 14, 2, 35, 201, 4],\n",
              " [12, 14, 2, 35, 201, 4, 41],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10, 202],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10, 202, 203],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10, 202, 203, 28],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10, 202, 203, 28, 7],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10, 202, 203, 28, 7, 20],\n",
              " [12, 14, 2, 35, 201, 4, 41, 10, 202, 203, 28, 7, 20, 204],\n",
              " [76, 30],\n",
              " [76, 30, 1],\n",
              " [76, 30, 1, 205],\n",
              " [76, 30, 1, 205, 4],\n",
              " [76, 30, 1, 205, 4, 77],\n",
              " [76, 30, 1, 205, 4, 77, 78],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79, 80],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79, 80, 3],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79, 80, 3, 206],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79, 80, 3, 206, 60],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79, 80, 3, 206, 60, 13],\n",
              " [76, 30, 1, 205, 4, 77, 78, 3, 46, 1, 6, 2, 79, 80, 3, 206, 60, 13, 52],\n",
              " [207, 9],\n",
              " [207, 9, 5],\n",
              " [207, 9, 5, 26],\n",
              " [207, 9, 5, 26, 27],\n",
              " [207, 9, 5, 26, 27, 208],\n",
              " [207, 9, 5, 26, 27, 208, 7],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210, 4],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210, 4, 37],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210, 4, 37, 74],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210, 4, 37, 74, 23],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210, 4, 37, 74, 23, 211],\n",
              " [207, 9, 5, 26, 27, 208, 7, 209, 210, 4, 37, 74, 23, 211, 212],\n",
              " [14, 2],\n",
              " [14, 2, 3],\n",
              " [14, 2, 3, 6],\n",
              " [14, 2, 3, 6, 2],\n",
              " [14, 2, 3, 6, 2, 213],\n",
              " [14, 2, 3, 6, 2, 213, 16],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4, 45],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4, 45, 81],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4, 45, 81, 4],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4, 45, 81, 4, 2],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4, 45, 81, 4, 2, 21],\n",
              " [14, 2, 3, 6, 2, 213, 16, 214, 4, 45, 81, 4, 2, 21, 58],\n",
              " [22, 16],\n",
              " [22, 16, 215],\n",
              " [22, 16, 215, 216],\n",
              " [22, 16, 215, 216, 21],\n",
              " [22, 16, 215, 216, 21, 82],\n",
              " [22, 16, 215, 216, 21, 82, 2],\n",
              " [83, 2],\n",
              " [83, 2, 3],\n",
              " [83, 2, 3, 84],\n",
              " [83, 2, 3, 84, 2],\n",
              " [83, 2, 3, 84, 2, 82],\n",
              " [83, 2, 3, 84, 2, 82, 2],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40, 47],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40, 47, 5],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40, 47, 5, 72],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40, 47, 5, 72, 18],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40, 47, 5, 72, 18, 26],\n",
              " [83, 2, 3, 84, 2, 82, 2, 217, 40, 47, 5, 72, 18, 26, 27],\n",
              " [35, 218],\n",
              " [35, 218, 36],\n",
              " [35, 218, 36, 219],\n",
              " [35, 218, 36, 219, 4],\n",
              " [35, 218, 36, 219, 4, 20],\n",
              " [35, 218, 36, 219, 4, 20, 56],\n",
              " [35, 218, 36, 219, 4, 20, 56, 5],\n",
              " [35, 218, 36, 219, 4, 20, 56, 5, 220],\n",
              " [35, 218, 36, 219, 4, 20, 56, 5, 220, 33],\n",
              " [35, 218, 36, 219, 4, 20, 56, 5, 220, 33, 8],\n",
              " [35, 218, 36, 219, 4, 20, 56, 5, 220, 33, 8, 221],\n",
              " [12, 222],\n",
              " [12, 222, 83],\n",
              " [12, 222, 83, 2],\n",
              " [12, 222, 83, 2, 42],\n",
              " [12, 222, 83, 2, 42, 223],\n",
              " [12, 222, 83, 2, 42, 223, 40],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224, 9],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224, 9, 225],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224, 9, 225, 226],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224, 9, 225, 226, 12],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224, 9, 225, 226, 12, 1],\n",
              " [12, 222, 83, 2, 42, 223, 40, 47, 3, 224, 9, 225, 226, 12, 1, 8],\n",
              " [227, 228],\n",
              " [227, 228, 28],\n",
              " [227, 228, 28, 85],\n",
              " [227, 228, 28, 85, 229],\n",
              " [227, 228, 28, 85, 229, 230],\n",
              " [227, 228, 28, 85, 229, 230, 84],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44, 12],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44, 12, 22],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44, 12, 22, 7],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44, 12, 22, 7, 34],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44, 12, 22, 7, 34, 62],\n",
              " [227, 228, 28, 85, 229, 230, 84, 2, 10, 7, 44, 12, 22, 7, 34, 62, 5],\n",
              " [231, 38],\n",
              " [231, 38, 86],\n",
              " [231, 38, 86, 13],\n",
              " [231, 38, 86, 13, 55],\n",
              " [231, 38, 86, 13, 55, 37],\n",
              " [231, 38, 86, 13, 55, 37, 232],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69, 235],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69, 235, 12],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69, 235, 12, 236],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69, 235, 12, 236, 5],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69, 235, 12, 236, 5, 237],\n",
              " [231, 38, 86, 13, 55, 37, 232, 12, 37, 233, 234, 69, 235, 12, 236, 5, 237, 1],\n",
              " [231,\n",
              "  38,\n",
              "  86,\n",
              "  13,\n",
              "  55,\n",
              "  37,\n",
              "  232,\n",
              "  12,\n",
              "  37,\n",
              "  233,\n",
              "  234,\n",
              "  69,\n",
              "  235,\n",
              "  12,\n",
              "  236,\n",
              "  5,\n",
              "  237,\n",
              "  1,\n",
              "  238],\n",
              " [6, 2],\n",
              " [6, 2, 11],\n",
              " [6, 2, 11, 24],\n",
              " [6, 2, 11, 24, 18],\n",
              " [6, 2, 11, 24, 18, 53],\n",
              " [6, 2, 11, 24, 18, 53, 11],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20, 241],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20, 241, 30],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20, 241, 30, 7],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20, 241, 30, 7, 242],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20, 241, 30, 7, 242, 4],\n",
              " [6, 2, 11, 24, 18, 53, 11, 24, 239, 5, 240, 1, 20, 241, 30, 7, 242, 4, 8],\n",
              " [6,\n",
              "  2,\n",
              "  11,\n",
              "  24,\n",
              "  18,\n",
              "  53,\n",
              "  11,\n",
              "  24,\n",
              "  239,\n",
              "  5,\n",
              "  240,\n",
              "  1,\n",
              "  20,\n",
              "  241,\n",
              "  30,\n",
              "  7,\n",
              "  242,\n",
              "  4,\n",
              "  8,\n",
              "  243],\n",
              " [87, 3],\n",
              " [87, 3, 244],\n",
              " [87, 3, 244, 39],\n",
              " [87, 3, 244, 39, 245],\n",
              " [87, 3, 244, 39, 245, 246],\n",
              " [87, 3, 244, 39, 245, 246, 88],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249, 3],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249, 3, 250],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249, 3, 250, 251],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249, 3, 250, 251, 252],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249, 3, 250, 251, 252, 1],\n",
              " [87, 3, 244, 39, 245, 246, 88, 5, 247, 248, 249, 3, 250, 251, 252, 1, 8],\n",
              " [6, 11],\n",
              " [6, 11, 24],\n",
              " [6, 11, 24, 253],\n",
              " [6, 11, 24, 253, 4],\n",
              " [6, 11, 24, 253, 4, 254],\n",
              " [6, 11, 24, 253, 4, 254, 19],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258, 1],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258, 1, 259],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258, 1, 259, 31],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258, 1, 259, 31, 5],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258, 1, 259, 31, 5, 51],\n",
              " [6, 11, 24, 253, 4, 254, 19, 4, 255, 256, 73, 257, 258, 1, 259, 31, 5, 51, 3],\n",
              " [50, 1],\n",
              " [50, 1, 89],\n",
              " [50, 1, 89, 18],\n",
              " [50, 1, 89, 18, 260],\n",
              " [50, 1, 89, 18, 260, 35],\n",
              " [50, 1, 89, 18, 260, 35, 261],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30, 1],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30, 1, 17],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30, 1, 17, 10],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30, 1, 17, 10, 48],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30, 1, 17, 10, 48, 90],\n",
              " [50, 1, 89, 18, 260, 35, 261, 4, 262, 30, 1, 17, 10, 48, 90, 91],\n",
              " [1, 33],\n",
              " [1, 33, 3],\n",
              " [1, 33, 3, 92],\n",
              " [1, 33, 3, 92, 19],\n",
              " [1, 33, 3, 92, 19, 4],\n",
              " [1, 33, 3, 92, 19, 4, 7],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6, 11],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6, 11, 17],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6, 11, 17, 16],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6, 11, 17, 16, 48],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6, 11, 17, 16, 48, 263],\n",
              " [1, 33, 3, 92, 19, 4, 7, 6, 11, 17, 16, 48, 263, 19],\n",
              " [1, 33],\n",
              " [1, 33, 31],\n",
              " [1, 33, 31, 10],\n",
              " [1, 33, 31, 10, 93],\n",
              " [1, 33, 31, 10, 93, 1],\n",
              " [1, 33, 31, 10, 93, 1, 6],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3, 1],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3, 1, 92],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3, 1, 92, 31],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3, 1, 92, 31, 10],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3, 1, 92, 31, 10, 93],\n",
              " [1, 33, 31, 10, 93, 1, 6, 2, 34, 264, 1, 8, 13, 43, 3, 1, 92, 31, 10, 93, 1],\n",
              " [1,\n",
              "  33,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  34,\n",
              "  264,\n",
              "  1,\n",
              "  8,\n",
              "  13,\n",
              "  43,\n",
              "  3,\n",
              "  1,\n",
              "  92,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  265],\n",
              " [1,\n",
              "  33,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  34,\n",
              "  264,\n",
              "  1,\n",
              "  8,\n",
              "  13,\n",
              "  43,\n",
              "  3,\n",
              "  1,\n",
              "  92,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  265,\n",
              "  89],\n",
              " [1,\n",
              "  33,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  34,\n",
              "  264,\n",
              "  1,\n",
              "  8,\n",
              "  13,\n",
              "  43,\n",
              "  3,\n",
              "  1,\n",
              "  92,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  265,\n",
              "  89,\n",
              "  18],\n",
              " [1,\n",
              "  33,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  34,\n",
              "  264,\n",
              "  1,\n",
              "  8,\n",
              "  13,\n",
              "  43,\n",
              "  3,\n",
              "  1,\n",
              "  92,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  265,\n",
              "  89,\n",
              "  18,\n",
              "  266],\n",
              " [1,\n",
              "  33,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  34,\n",
              "  264,\n",
              "  1,\n",
              "  8,\n",
              "  13,\n",
              "  43,\n",
              "  3,\n",
              "  1,\n",
              "  92,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  265,\n",
              "  89,\n",
              "  18,\n",
              "  266,\n",
              "  10],\n",
              " [1,\n",
              "  33,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  34,\n",
              "  264,\n",
              "  1,\n",
              "  8,\n",
              "  13,\n",
              "  43,\n",
              "  3,\n",
              "  1,\n",
              "  92,\n",
              "  31,\n",
              "  10,\n",
              "  93,\n",
              "  1,\n",
              "  265,\n",
              "  89,\n",
              "  18,\n",
              "  266,\n",
              "  10,\n",
              "  267],\n",
              " [75, 44],\n",
              " [75, 44, 48],\n",
              " [75, 44, 48, 46],\n",
              " [75, 44, 48, 46, 268],\n",
              " [75, 44, 48, 46, 268, 29],\n",
              " [75, 44, 48, 46, 268, 29, 68],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269, 94],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269, 94, 12],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269, 94, 12, 27],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269, 94, 12, 27, 3],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269, 94, 12, 27, 3, 76],\n",
              " [75, 44, 48, 46, 268, 29, 68, 77, 78, 5, 269, 94, 12, 27, 3, 76, 80],\n",
              " [1, 87],\n",
              " [1, 87, 3],\n",
              " [1, 87, 3, 270],\n",
              " [1, 87, 3, 270, 4],\n",
              " [1, 87, 3, 270, 4, 1],\n",
              " [1, 87, 3, 270, 4, 1, 271],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19, 12],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19, 12, 37],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19, 12, 37, 274],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19, 12, 37, 274, 5],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19, 12, 37, 274, 5, 275],\n",
              " [1, 87, 3, 270, 4, 1, 271, 28, 272, 273, 30, 1, 19, 12, 37, 274, 5, 275, 1],\n",
              " [1,\n",
              "  87,\n",
              "  3,\n",
              "  270,\n",
              "  4,\n",
              "  1,\n",
              "  271,\n",
              "  28,\n",
              "  272,\n",
              "  273,\n",
              "  30,\n",
              "  1,\n",
              "  19,\n",
              "  12,\n",
              "  37,\n",
              "  274,\n",
              "  5,\n",
              "  275,\n",
              "  1,\n",
              "  34],\n",
              " [1,\n",
              "  87,\n",
              "  3,\n",
              "  270,\n",
              "  4,\n",
              "  1,\n",
              "  271,\n",
              "  28,\n",
              "  272,\n",
              "  273,\n",
              "  30,\n",
              "  1,\n",
              "  19,\n",
              "  12,\n",
              "  37,\n",
              "  274,\n",
              "  5,\n",
              "  275,\n",
              "  1,\n",
              "  34,\n",
              "  88],\n",
              " [90, 91],\n",
              " [90, 91, 3],\n",
              " [90, 91, 3, 46],\n",
              " [90, 91, 3, 46, 276],\n",
              " [90, 91, 3, 46, 276, 7],\n",
              " [90, 91, 3, 46, 276, 7, 11],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27, 3],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27, 3, 277],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27, 3, 277, 13],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27, 3, 277, 13, 85],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27, 3, 277, 13, 85, 94],\n",
              " [90, 91, 3, 46, 276, 7, 11, 17, 5, 26, 27, 3, 277, 13, 85, 94, 278],\n",
              " [279, 280],\n",
              " [279, 280, 1],\n",
              " [279, 280, 1, 79],\n",
              " [279, 280, 1, 79, 281],\n",
              " [279, 280, 1, 79, 281, 282],\n",
              " [279, 280, 1, 79, 281, 282, 38],\n",
              " [279, 280, 1, 79, 281, 282, 38, 86],\n",
              " [1, 283],\n",
              " [1, 283, 284],\n",
              " [1, 283, 284, 1],\n",
              " [1, 283, 284, 1, 95],\n",
              " [1, 283, 284, 1, 95, 61],\n",
              " [1, 283, 284, 1, 95, 61, 4],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11, 17],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11, 17, 12],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11, 17, 12, 1],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11, 17, 12, 1, 95],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11, 17, 12, 1, 95, 285],\n",
              " [1, 283, 284, 1, 95, 61, 4, 6, 11, 17, 12, 1, 95, 285, 286],\n",
              " [6, 2],\n",
              " [6, 2, 29],\n",
              " [6, 2, 29, 16],\n",
              " [6, 2, 29, 16, 287],\n",
              " [6, 2, 29, 16, 287, 288],\n",
              " [6, 2, 29, 16, 287, 288, 3],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11, 24],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11, 24, 5],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11, 24, 5, 290],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11, 24, 5, 290, 64],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11, 24, 5, 290, 64, 291],\n",
              " [6, 2, 29, 16, 287, 288, 3, 289, 16, 45, 81, 4, 11, 24, 5, 290, 64, 291, 18],\n",
              " [6,\n",
              "  2,\n",
              "  29,\n",
              "  16,\n",
              "  287,\n",
              "  288,\n",
              "  3,\n",
              "  289,\n",
              "  16,\n",
              "  45,\n",
              "  81,\n",
              "  4,\n",
              "  11,\n",
              "  24,\n",
              "  5,\n",
              "  290,\n",
              "  64,\n",
              "  291,\n",
              "  18,\n",
              "  47],\n",
              " [6,\n",
              "  2,\n",
              "  29,\n",
              "  16,\n",
              "  287,\n",
              "  288,\n",
              "  3,\n",
              "  289,\n",
              "  16,\n",
              "  45,\n",
              "  81,\n",
              "  4,\n",
              "  11,\n",
              "  24,\n",
              "  5,\n",
              "  290,\n",
              "  64,\n",
              "  291,\n",
              "  18,\n",
              "  47,\n",
              "  13],\n",
              " [6,\n",
              "  2,\n",
              "  29,\n",
              "  16,\n",
              "  287,\n",
              "  288,\n",
              "  3,\n",
              "  289,\n",
              "  16,\n",
              "  45,\n",
              "  81,\n",
              "  4,\n",
              "  11,\n",
              "  24,\n",
              "  5,\n",
              "  290,\n",
              "  64,\n",
              "  291,\n",
              "  18,\n",
              "  47,\n",
              "  13,\n",
              "  70]]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Max_len= max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "cP1Z1Cgg9UJG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 'input_sequences' is a list of sequences that you want to pad\n",
        "# 'Max_len' is the desired maximum sequence length\n",
        "# 'padding='pre'' specifies that padding should be added to the beginning of sequences\n",
        "\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=Max_len, padding='pre')\n",
        "\n"
      ],
      "metadata": {
        "id": "qjmkWE9qHKpZ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO2Zk60rHKse",
        "outputId": "7a9c4f03-d593-4e73-b236-074e1d8b57a0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   6,   2],\n",
              "       [  0,   0,   0, ...,   6,   2,  10],\n",
              "       [  0,   0,   0, ...,   2,  10,   7],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 291,  18,  47],\n",
              "       [  0,   0,   0, ...,  18,  47,  13],\n",
              "       [  0,   0,   0, ...,  47,  13,  70]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "W2HDXZtBHKvD"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftDAo2Q9UMm",
        "outputId": "4b62f010-a537-4766-a55c-563fb5b33dff"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   6],\n",
              "       [  0,   0,   0, ...,   0,   6,   2],\n",
              "       [  0,   0,   0, ...,   6,   2,  10],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  64, 291,  18],\n",
              "       [  0,   0,   0, ..., 291,  18,  47],\n",
              "       [  0,   0,   0, ...,  18,  47,  13]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "aEyhpQhWUC47"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5II1G7MoUb5B",
        "outputId": "84bc7f96-91cc-4424-d7fd-635ce2073208"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2,  10,   7,  49,   4,  14,   2,  22,  10,  96,   7,  11,  17,\n",
              "        23,  97,  18,  38,  19,  11,  24,  98,   5,  99,   1, 100,   4,\n",
              "         1,  20, 101, 102,  25, 103, 104, 105,   9, 106,  25, 107, 108,\n",
              "         4,   8, 109,   7,  11,  17,  23,   7, 110,  31,  32, 111,  26,\n",
              "       112,  27, 114,  19,  32, 115,   5,  50,   3,  51,  13,  52,   2,\n",
              "       116, 117,  53, 118, 119, 120,   3,  54,  15, 121, 122, 123,   3,\n",
              "       124, 125, 126,  20,  56,   6,   2, 127, 128, 129, 130, 131,   3,\n",
              "        54,  21, 132, 133, 134, 135, 136, 137,   3, 138, 139, 140, 141,\n",
              "        21,  58,  21, 142, 143,  57,  21, 144, 145, 146,   6,   2,  10,\n",
              "         7,  49,   4,  14,   2, 147, 148, 149, 150,   6,   2, 151,  60,\n",
              "        25, 152,  14,   2,  28,   1,  61,   8,  15,   9, 153,  23,   3,\n",
              "         1, 154,  12,  22,   9,  62,   2,  29, 155,  63,   8,   5,  26,\n",
              "       156,  15,  64,  41,  16, 157,  25,   1,  33,   8,  13,   1,  34,\n",
              "         3, 158,  65, 159,  42, 160, 161,  15,   9,  42, 162,  66,   8,\n",
              "         9, 163, 164,  15,  59,   9, 165, 166, 167,  30,  36,  67,  43,\n",
              "         5, 168,   9,  65,   7,  63, 169,   2, 170,  36,   4,   8,  67,\n",
              "        43,  15,  10, 171, 172,  23,  14,   2,  29,  32, 173,   3,  44,\n",
              "        66,   8,  68, 174,   3, 175,   3,   9, 176, 177, 178,  36,   4,\n",
              "         1, 180,  69,  20, 181,  13,  70, 182, 183,  15,  71, 184,   7,\n",
              "       185,   4, 186,   4,  45, 187,  71, 188,   5,  72,  28, 189, 190,\n",
              "       191, 192, 193,   6,   2,  29,  32, 194,  41, 195, 196, 197,  16,\n",
              "       198, 199,   5, 200,  73,  74,  25,  75,  14,   2,  35, 201,   4,\n",
              "        41,  10, 202, 203,  28,   7,  20, 204,  30,   1, 205,   4,  77,\n",
              "        78,   3,  46,   1,   6,   2,  79,  80,   3, 206,  60,  13,  52,\n",
              "         9,   5,  26,  27, 208,   7, 209, 210,   4,  37,  74,  23, 211,\n",
              "       212,   2,   3,   6,   2, 213,  16, 214,   4,  45,  81,   4,   2,\n",
              "        21,  58,  16, 215, 216,  21,  82,   2,   2,   3,  84,   2,  82,\n",
              "         2, 217,  40,  47,   5,  72,  18,  26,  27, 218,  36, 219,   4,\n",
              "        20,  56,   5, 220,  33,   8, 221, 222,  83,   2,  42, 223,  40,\n",
              "        47,   3, 224,   9, 225, 226,  12,   1,   8, 228,  28,  85, 229,\n",
              "       230,  84,   2,  10,   7,  44,  12,  22,   7,  34,  62,   5,  38,\n",
              "        86,  13,  55,  37, 232,  12,  37, 233, 234,  69, 235,  12, 236,\n",
              "         5, 237,   1, 238,   2,  11,  24,  18,  53,  11,  24, 239,   5,\n",
              "       240,   1,  20, 241,  30,   7, 242,   4,   8, 243,   3, 244,  39,\n",
              "       245, 246,  88,   5, 247, 248, 249,   3, 250, 251, 252,   1,   8,\n",
              "        11,  24, 253,   4, 254,  19,   4, 255, 256,  73, 257, 258,   1,\n",
              "       259,  31,   5,  51,   3,   1,  89,  18, 260,  35, 261,   4, 262,\n",
              "        30,   1,  17,  10,  48,  90,  91,  33,   3,  92,  19,   4,   7,\n",
              "         6,  11,  17,  16,  48, 263,  19,  33,  31,  10,  93,   1,   6,\n",
              "         2,  34, 264,   1,   8,  13,  43,   3,   1,  92,  31,  10,  93,\n",
              "         1, 265,  89,  18, 266,  10, 267,  44,  48,  46, 268,  29,  68,\n",
              "        77,  78,   5, 269,  94,  12,  27,   3,  76,  80,  87,   3, 270,\n",
              "         4,   1, 271,  28, 272, 273,  30,   1,  19,  12,  37, 274,   5,\n",
              "       275,   1,  34,  88,  91,   3,  46, 276,   7,  11,  17,   5,  26,\n",
              "        27,   3, 277,  13,  85,  94, 278, 280,   1,  79, 281, 282,  38,\n",
              "        86, 283, 284,   1,  95,  61,   4,   6,  11,  17,  12,   1,  95,\n",
              "       285, 286,   2,  29,  16, 287, 288,   3, 289,  16,  45,  81,   4,\n",
              "        11,  24,   5, 290,  64, 291,  18,  47,  13,  70], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzdUHZDgUC7n",
        "outputId": "a6ad1a23-f605-45cc-8b3d-0407fea5fa3c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUO3uNjVUC-b",
        "outputId": "cdec5453-82db-4cd7-e70d-3ed8c63efc00"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621,)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "# Assuming 'y' contains integer labels for your classes\n",
        "# 'num_classes' specifies the total number of classes in your classification task\n",
        "y_one_hot = to_categorical(y, num_classes=292)\n"
      ],
      "metadata": {
        "id": "vAUZJPL3UDAi"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tckmv0IJUDDl",
        "outputId": "b0bc0d10-e4f5-46d3-b54c-1dd7f77a0738"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(621, 292)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM, Dense\n"
      ],
      "metadata": {
        "id": "ZpqRXaD4r7oK"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a Sequential model with an Embedding layer, LSTM layer, and a Dense layer for text generation.\n",
        "model=Sequential()\n",
        "model.add(Embedding(292,100, input_length=26))\n",
        "model.add(LSTM(130))\n",
        "model.add(Dense(292, activation='softmax'))"
      ],
      "metadata": {
        "id": "t_eKtW-Fx4mS"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "3WEQA4p6zWgy"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQzOVPNi0FbT",
        "outputId": "eb2cb471-fd8c-4c80-c72f-1f6d7a3b0299"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 26, 100)           29200     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 130)               120120    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 292)               38252     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 187572 (732.70 KB)\n",
            "Trainable params: 187572 (732.70 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUC58byVFLP4",
        "outputId": "7c4b63a8-e3a7-40e7-aaf7-2ce50fd5a72f"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 10s 165ms/step - loss: 5.6221 - accuracy: 0.0306\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 2s 112ms/step - loss: 5.2934 - accuracy: 0.0370\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 5.1689 - accuracy: 0.0338\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 1s 61ms/step - loss: 5.1217 - accuracy: 0.0403\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 2s 89ms/step - loss: 5.1016 - accuracy: 0.0564\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 5.0680 - accuracy: 0.0531\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 1s 37ms/step - loss: 5.0176 - accuracy: 0.0821\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 4.9591 - accuracy: 0.0580\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 26ms/step - loss: 4.8623 - accuracy: 0.0805\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 1s 45ms/step - loss: 4.7492 - accuracy: 0.0886\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 4.6172 - accuracy: 0.1031\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 1s 35ms/step - loss: 4.4678 - accuracy: 0.1159\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 1s 47ms/step - loss: 4.3097 - accuracy: 0.1449\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 26ms/step - loss: 4.1279 - accuracy: 0.1578\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 3.9633 - accuracy: 0.1820\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 3.7745 - accuracy: 0.1965\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 3.6085 - accuracy: 0.2045\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 3.4298 - accuracy: 0.2464\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 3.2683 - accuracy: 0.2528\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 1s 36ms/step - loss: 3.0907 - accuracy: 0.2963\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 2.9335 - accuracy: 0.3221\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 2.7948 - accuracy: 0.3591\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 2.6264 - accuracy: 0.4219\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 2.4848 - accuracy: 0.4477\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 2.3529 - accuracy: 0.4911\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 2.2179 - accuracy: 0.5362\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 2.1008 - accuracy: 0.5733\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1.9702 - accuracy: 0.6103\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.8608 - accuracy: 0.6683\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 1.7548 - accuracy: 0.7037\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 1.6440 - accuracy: 0.7391\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 1.5567 - accuracy: 0.7826\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 1.4569 - accuracy: 0.8068\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 1.3772 - accuracy: 0.8100\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 1.2991 - accuracy: 0.8486\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 1.2198 - accuracy: 0.8663\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 1.1500 - accuracy: 0.8873\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0820 - accuracy: 0.9066\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 1.0144 - accuracy: 0.9098\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.9573 - accuracy: 0.9211\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.9029 - accuracy: 0.9324\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.8529 - accuracy: 0.9388\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.8036 - accuracy: 0.9436\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 1s 16ms/step - loss: 0.7609 - accuracy: 0.9501\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7123 - accuracy: 0.9581\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.6827 - accuracy: 0.9630\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6468 - accuracy: 0.9597\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6089 - accuracy: 0.9597\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.5772 - accuracy: 0.9597\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.9694\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.9742\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.9742\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.9726\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.4502 - accuracy: 0.9742\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 1s 26ms/step - loss: 0.4261 - accuracy: 0.9726\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.9742\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3856 - accuracy: 0.9742\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.9710\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.9710\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3396 - accuracy: 0.9742\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3267 - accuracy: 0.9726\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3116 - accuracy: 0.9758\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.2984 - accuracy: 0.9726\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2885 - accuracy: 0.9742\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.2762 - accuracy: 0.9742\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2676 - accuracy: 0.9726\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2581 - accuracy: 0.9742\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2509 - accuracy: 0.9710\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.9742\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2305 - accuracy: 0.9742\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9742\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9726\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2094 - accuracy: 0.9742\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2021 - accuracy: 0.9742\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1970 - accuracy: 0.9726\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1881 - accuracy: 0.9758\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1853 - accuracy: 0.9726\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1819 - accuracy: 0.9775\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1748 - accuracy: 0.9742\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.1699 - accuracy: 0.9758\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.9775\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1629 - accuracy: 0.9758\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.9758\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1529 - accuracy: 0.9758\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1491 - accuracy: 0.9791\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.1460 - accuracy: 0.9742\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.1434 - accuracy: 0.9742\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1386 - accuracy: 0.9710\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.1351 - accuracy: 0.9775\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9726\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1288 - accuracy: 0.9758\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9742\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1245 - accuracy: 0.9775\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.1235 - accuracy: 0.9742\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.9791\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9742\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9758\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.1131 - accuracy: 0.9742\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9758\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.9775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d41ee2a6230>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='what is Deep'\n",
        "tokn_text= tokenizer.texts_to_sequences([text])[0]"
      ],
      "metadata": {
        "id": "FenDqIo9HhjB"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_text= pad_sequences([tokn_text], maxlen=26, padding=\"pre\")"
      ],
      "metadata": {
        "id": "uG_IXhBJIT-j"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbjCQ2PEI9Bo",
        "outputId": "6b91e36d-a9f9-45b4-b94f-d9f3816d411e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0, 10,  6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(padded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdYlImvmJwT2",
        "outputId": "994f550a-68c8-4d93-df62-ff0e4ec938d6"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 365ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.60626779e-09, 1.23012767e-04, 9.81046379e-01, 1.98365778e-05,\n",
              "        1.11766225e-04, 2.21009777e-05, 6.41967563e-05, 1.52885987e-04,\n",
              "        5.08441044e-05, 1.81788491e-05, 1.86489371e-04, 1.62703153e-02,\n",
              "        7.13766494e-05, 8.40889243e-07, 6.38454512e-05, 4.93224361e-05,\n",
              "        5.18480723e-04, 6.07061168e-07, 1.68418774e-05, 1.42460622e-05,\n",
              "        1.26802649e-06, 1.39616468e-05, 6.60726619e-06, 2.44474122e-05,\n",
              "        1.30468907e-05, 7.99750705e-06, 5.27535526e-09, 9.25887278e-09,\n",
              "        1.48001959e-06, 2.25877811e-04, 4.59194125e-04, 1.31660590e-05,\n",
              "        6.15831814e-05, 2.47636194e-06, 1.49608093e-06, 1.96017172e-05,\n",
              "        2.39190631e-05, 6.74257365e-07, 1.93336845e-07, 5.21142740e-10,\n",
              "        3.71907625e-08, 1.41736353e-04, 1.63308385e-07, 5.87127147e-09,\n",
              "        3.95752477e-06, 2.69562946e-07, 1.31430058e-08, 5.61584386e-07,\n",
              "        1.72433511e-06, 2.57373122e-05, 1.05779878e-10, 1.29692312e-09,\n",
              "        1.15387984e-08, 3.62445256e-08, 3.39049372e-10, 2.89919964e-08,\n",
              "        2.38920439e-09, 2.94211988e-09, 1.27737154e-09, 1.30956437e-07,\n",
              "        3.20245626e-08, 6.48156151e-09, 2.03954986e-08, 4.26112547e-06,\n",
              "        6.18134777e-07, 1.07502780e-08, 1.52193240e-06, 6.20458195e-07,\n",
              "        7.87889178e-07, 5.38148072e-07, 4.62712135e-09, 2.59594401e-07,\n",
              "        1.76218179e-10, 2.07808824e-07, 6.91711827e-11, 6.18621199e-09,\n",
              "        1.35263889e-09, 3.78002187e-06, 1.67762728e-08, 2.08896631e-06,\n",
              "        8.07117786e-08, 1.12474986e-07, 3.35647883e-08, 2.20674065e-05,\n",
              "        1.20748336e-06, 5.13775376e-07, 5.74680783e-08, 7.65764753e-07,\n",
              "        6.64513777e-08, 1.52004679e-06, 3.41503643e-08, 7.45622003e-07,\n",
              "        9.85585444e-08, 1.27069768e-07, 2.27808639e-09, 8.22657398e-07,\n",
              "        1.29661530e-07, 6.95533231e-07, 1.76072305e-07, 5.93762550e-09,\n",
              "        2.26068607e-07, 6.17860652e-09, 1.54951896e-09, 1.80967277e-08,\n",
              "        4.74043582e-10, 1.95875316e-09, 2.16000662e-09, 3.50608548e-06,\n",
              "        1.71676177e-07, 4.51122872e-08, 4.66203801e-07, 5.55732071e-10,\n",
              "        8.70736261e-10, 2.24784702e-09, 6.94698272e-08, 1.02664166e-09,\n",
              "        4.36661594e-06, 1.49337595e-07, 1.84954285e-06, 9.26457300e-10,\n",
              "        1.55639379e-09, 4.12591561e-07, 2.31085173e-09, 5.91657816e-08,\n",
              "        1.32811264e-08, 7.46650575e-10, 1.60222726e-07, 4.16999086e-07,\n",
              "        3.08442836e-08, 6.12465723e-09, 1.23801913e-09, 5.30000399e-09,\n",
              "        5.48660317e-08, 3.77222475e-10, 2.65980948e-09, 1.83772588e-08,\n",
              "        2.86240076e-09, 1.91806571e-10, 1.27454061e-10, 2.40233842e-08,\n",
              "        1.09440845e-09, 7.09704695e-09, 7.38684169e-10, 4.30680247e-09,\n",
              "        1.32002478e-10, 7.03713177e-09, 4.42336621e-08, 2.45956045e-07,\n",
              "        2.43589167e-08, 1.08021903e-09, 2.70833851e-07, 5.39356257e-08,\n",
              "        7.85660390e-08, 3.92823978e-08, 8.18116064e-08, 6.80876474e-06,\n",
              "        3.13771942e-08, 2.01900408e-09, 6.82923551e-10, 1.94820700e-07,\n",
              "        3.48848661e-09, 1.00210806e-09, 3.89452970e-10, 1.29088662e-09,\n",
              "        4.51171678e-09, 2.79347612e-09, 7.62458896e-08, 1.34189008e-07,\n",
              "        1.43028267e-09, 1.56913937e-09, 3.33141634e-06, 8.62076277e-08,\n",
              "        1.51963354e-06, 5.94659821e-10, 1.27723343e-08, 7.91085242e-09,\n",
              "        1.07842855e-08, 9.11415776e-10, 3.40242812e-09, 3.06646530e-09,\n",
              "        1.71321602e-07, 2.70474243e-09, 3.89627797e-09, 3.01906944e-08,\n",
              "        1.54821702e-08, 4.14097428e-07, 1.47539436e-06, 2.37709621e-08,\n",
              "        1.83049394e-07, 3.25401260e-07, 9.14110676e-10, 2.66194604e-07,\n",
              "        8.91549305e-08, 2.03379969e-07, 3.56577545e-09, 1.75299510e-06,\n",
              "        3.74687126e-09, 6.71371581e-08, 2.04286588e-09, 1.80446147e-08,\n",
              "        8.42349177e-11, 2.00698000e-08, 7.50723999e-08, 1.70283976e-09,\n",
              "        1.34708023e-09, 8.66945982e-07, 1.02563867e-07, 3.09137649e-09,\n",
              "        5.51953804e-07, 1.25588940e-06, 1.44499177e-08, 3.83657621e-08,\n",
              "        4.75379380e-09, 5.21335892e-07, 1.36103939e-09, 8.81698359e-09,\n",
              "        2.80286554e-06, 9.44513019e-08, 6.61863595e-08, 1.08745546e-07,\n",
              "        9.89381577e-10, 1.72938840e-07, 2.35193020e-05, 6.06713879e-09,\n",
              "        3.31920180e-09, 3.91715682e-09, 9.22305698e-09, 1.06693177e-09,\n",
              "        2.17583747e-07, 2.12394582e-08, 4.26612223e-06, 2.49826893e-09,\n",
              "        1.78783044e-10, 2.33930764e-10, 7.02680722e-08, 9.82095116e-08,\n",
              "        1.71756426e-07, 5.90166083e-10, 2.96525182e-09, 1.38919845e-07,\n",
              "        9.76556258e-09, 4.15920365e-09, 1.04823471e-06, 3.86080821e-08,\n",
              "        3.54625698e-08, 8.57072109e-07, 1.02500786e-09, 1.15042628e-10,\n",
              "        3.70218745e-09, 3.11279678e-08, 2.19787100e-09, 4.02255949e-07,\n",
              "        1.76723518e-07, 1.79565166e-06, 1.74965389e-05, 1.62194215e-06,\n",
              "        4.60050087e-09, 2.23639884e-09, 1.63653084e-07, 2.55524277e-08,\n",
              "        2.27709833e-07, 6.24093000e-09, 1.09587529e-06, 1.57425752e-08,\n",
              "        3.50091142e-07, 6.71176670e-09, 7.65310233e-08, 1.28621034e-08,\n",
              "        4.53013809e-06, 1.55528701e-09, 9.67222746e-09, 2.43633423e-07,\n",
              "        6.02466798e-07, 1.46248524e-08, 1.33759510e-08, 3.27940608e-09,\n",
              "        3.87924365e-06, 7.79706433e-09, 1.10196275e-07, 1.85921012e-09,\n",
              "        5.33268576e-07, 2.14100826e-08, 1.89955447e-08, 4.65501017e-07,\n",
              "        1.03745003e-06, 1.46908241e-09, 6.51017018e-09, 7.28060812e-09,\n",
              "        3.40676308e-07, 2.55803219e-08, 4.63872135e-10, 3.69017634e-08]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have previously defined the 'model' and 'padded_text' variables\n",
        "# Use the model to predict and find the index of the maximum value in the prediction\n",
        "# Iterate through the tokenizer's word_index to find the word corresponding to 'word_num'\n",
        "import numpy as np\n",
        "word_num = np.argmax(model.predict(padded_text))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index == word_num:\n",
        "        # Print the corresponding word\n",
        "        print(word)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ln_29qMJwW4",
        "outputId": "46e34ff0-5558-403e-e65a-77a4ab024741"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a8LbAf2-JwZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EE1ISAEJwcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}